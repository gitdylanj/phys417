{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c542647",
   "metadata": {},
   "source": [
    "# Lab 5 Report: \n",
    "## Create Arthur Conan Doyle AI with RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87f0bdb8",
   "metadata": {},
   "source": [
    "### Name: Dylan Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d050509d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1595b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image # For displaying images in colab jupyter cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15441bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('lab5_exercise.png', width = 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f149d33a",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will train on the first N characters of the Sherlock Holmes book\n",
    "# Pick the size of your training data, i.e. N\n",
    "data_size_to_train = 10000\n",
    "\n",
    "# Load the Sherlock Holmes data up to data_size_to_train\n",
    "data = open('sherlock.txt', 'r').read()[10000:data_size_to_train + 10000]\n",
    "\n",
    "# Find the set of unique characters within the training data\n",
    "characters = sorted(list(set(data)))\n",
    "\n",
    "# total number of characters in the training data and number of unique characters\n",
    "data_size, vocab_size = len(data), len(characters)\n",
    "\n",
    "print(\"Data has {} characters, {} unique\".format(data_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Python Dictionary to map the characters to numbers and vice versa\n",
    "\n",
    "characters_to_num = {ch:i for i, ch in enumerate(characters)}\n",
    "\n",
    "num_to_characters = {i:ch for i, ch in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the character_to_num dictionary to map each character in the training dataset to a number\n",
    "\n",
    "data = list(data)\n",
    "for i, ch in enumerate(data):\n",
    "    data[i] = characters_to_num[ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd9faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cfe7863",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d29ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, input_size, hidden_size, num_layers, output_size):\n",
    "        \n",
    "        super(CharRNN, self).__init__()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim)\n",
    "\n",
    "        self.rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, nonlinearity='relu')\n",
    "\n",
    "        self.decoder = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        \n",
    "        embedding = self.embedding(input_seq)\n",
    "\n",
    "        output, hidden_state = self.rnn(embedding, hidden_state)\n",
    "\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        return output, hidden_state.detach()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50cac3a5",
   "metadata": {},
   "source": [
    "## Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c001665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "torch.manual_seed(25)\n",
    "\n",
    "# Define RNN network\n",
    "rnn = CharRNN(num_embeddings=vocab_size, embedding_dim=100, input_size=100, hidden_size=512, num_layers=3, output_size=vocab_size)\n",
    "\n",
    "# Define learning rate and epochs\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "\n",
    "# Size of the input sequence to be used during training and validation\n",
    "training_sequence_len = 50\n",
    "validation_sequence_len = 100\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# add .cuda() for GPU acceleration\n",
    "rnn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0b88a3d",
   "metadata": {},
   "source": [
    "## Identify Tracked Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9efa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking training loss per each input/target sequence fwd/bwd pass\n",
    "train_loss_list = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b818cf8",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a812d26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert training data into torch tensor and make it into vertical orientation (N, 1)\n",
    "# Attach .cuda() if using GPU\n",
    "data = torch.unsqueeze(torch.tensor(data), dim=1)\n",
    "\n",
    "# Training Loop ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    character_loc = np.random.randint(100)\n",
    "    iteration = 0\n",
    "    hidden_state = None\n",
    "    \n",
    "    # Sample and generate a text sequence after every epoch --------------------------------------------------------------\n",
    "    \n",
    "    while character_loc + training_sequence_len + 1 < data_size:\n",
    "\n",
    "        input_seq = data[character_loc:character_loc + training_sequence_len]\n",
    "        target_seq = data[character_loc + 1: character_loc + training_sequence_len + 1]\n",
    "\n",
    "        output, hidden_state = rnn(input_seq, hidden_state)\n",
    "       \n",
    "        loss = loss_fn(torch.squeeze(output), torch.squeeze(target_seq))\n",
    "\n",
    "        train_loss_list.append(loss.item())\n",
    "\n",
    "        # Backpropagate error\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        character_loc += training_sequence_len\n",
    "\n",
    "        iteration += 1\n",
    "    \n",
    "    print('----------------------------')\n",
    "    print(f\"Average training loss per epoch: {epoch}: {np.mean(train_loss_list[-iteration: ])}\")\n",
    "    character_loc = 0\n",
    "    hidden_state = None\n",
    "\n",
    "    rand_index = np.random.randint(data_size-1)\n",
    "    input_seq = data[rand_index:rand_index + 1]\n",
    "    with torch.no_grad():\n",
    "\n",
    "        while character_loc < validation_sequence_len:\n",
    "\n",
    "            output, hidden_state = rnn(input_seq, hidden_state)\n",
    "\n",
    "            output = torch.nn.functional.softmax(torch.squeeze(output), dim=0)\n",
    "            character_distribution = torch.distributions.Categorical(output)\n",
    "            character_num = character_distribution.sample()\n",
    "\n",
    "            print(num_to_characters[character_num.item()], end='')\n",
    "            \n",
    "\n",
    "            input_seq[0][0] = character_num.item()\n",
    "\n",
    "            character_loc += 1\n",
    "        print('\\n----------------------------')\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0442adb6",
   "metadata": {},
   "source": [
    "## Visualize & Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a validation text sequence that most closely resembles Sherlock Holmes style\n",
    "character_loc = 0\n",
    "hidden_state = None\n",
    "\n",
    "rand_index = np.random.randint(data_size-1)\n",
    "input_seq = data[rand_index:rand_index + 1]\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    while character_loc < 250:\n",
    "\n",
    "        output, hidden_state = rnn(input_seq, hidden_state)\n",
    "\n",
    "        output = torch.nn.functional.softmax(torch.squeeze(output), dim=0)\n",
    "        character_distribution = torch.distributions.Categorical(output)\n",
    "        character_num = character_distribution.sample()\n",
    "\n",
    "        print(num_to_characters[character_num.item()], end='')\n",
    "\n",
    "        input_seq[0][0] = character_num.item()\n",
    "\n",
    "        character_loc += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cfc511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn for prettier plot\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style = 'whitegrid', font_scale = 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss and rolling mean training loss with respect to iterations\n",
    "# Feel free to change the window size\n",
    "plt.figure(figsize = (10, 9))\n",
    "\n",
    "plt.plot(train_loss_list, linewidth = 3, label = 'Training Loss')\n",
    "plt.plot(np.convolve(train_loss_list, np.ones(100), 'valid') / 100, \n",
    "         linewidth = 3, label = 'Rolling Averaged Training Loss')\n",
    "plt.ylabel(\"training loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
